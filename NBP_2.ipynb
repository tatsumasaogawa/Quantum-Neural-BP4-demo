{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考: https://github.com/samn33/qlazy/blob/master/example/py/SurfaceCode/error_correction.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ナイーブな実装だと遅い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qlazy import QState\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "torch.set_printoptions(sci_mode=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeliefPropagation(nn.Module):\n",
    "    def __init__(self, num_nodes, num_edges):\n",
    "        super(BeliefPropagation, self).__init__()\n",
    "        \n",
    "        # 学習可能なパラメータの定義\n",
    "        self.b = nn.Parameter(torch.ones(num_nodes))\n",
    "        self.w = nn.Parameter(torch.ones(num_edges, num_nodes))\n",
    "\n",
    "        # b, w を 1 に固定した場合 (BP と等価)\n",
    "        # self.b = torch.ones(num_nodes)\n",
    "        # self.w = torch.ones(num_edges, num_nodes)\n",
    "    \n",
    "    def forward(self, l_v, h, s_c, iterations):\n",
    "        num_nodes = l_v.size(0)\n",
    "        num_edges = s_c.size(0)\n",
    "        \n",
    "        # メッセージ初期化\n",
    "        mu_v_to_c = torch.zeros(num_nodes, num_edges, dtype=torch.float32)\n",
    "        mu_c_to_v = torch.zeros(num_edges, num_nodes, dtype=torch.float32)\n",
    "        \n",
    "        # メッセージ伝播ループ\n",
    "        for t in range(iterations):\n",
    "            # メッセージ伝播 v -> c\n",
    "            # print(self.w)\n",
    "            # print(mu_c_to_v)\n",
    "            # print('mu * w')\n",
    "            # print(torch.matmul(mu_c_to_v, self.w))\n",
    "            # print('l_v * b_v')\n",
    "            # print(l_v.unsqueeze(1).size())\n",
    "            # print(self.b_v)\n",
    "            # print(l_v.unsqueeze(1) * self.b_v)\n",
    "            # print(torch.cat([self.b_v.unsqueeze(1), self.b_v.unsqueeze(1)], dim=1).size())\n",
    "            mu_v_to_c_new  = torch.zeros(num_nodes, num_edges, dtype=torch.float32)\n",
    "            print('ok')\n",
    "            \n",
    "            for v in range(num_nodes):\n",
    "                for c in range(num_edges):\n",
    "                    mu_v_to_c_new[v, c] = self.update_message_v_to_c(v, c, l_v, h, mu_c_to_v, self.w, self.b)\n",
    "            print('ok')\n",
    "            \n",
    "            # メッセージ伝播 c -> v\n",
    "            # print(s_c.unsqueeze(1))\n",
    "            # print(torch.ones(num_nodes, num_edges, dtype=torch.float32))\n",
    "            mu_c_to_v_new = torch.zeros(num_edges, num_nodes, dtype=torch.float32)\n",
    "\n",
    "            for c in range(num_edges):\n",
    "                # print(c)\n",
    "                for v in range(num_nodes):\n",
    "                    mu_c_to_v_new[c, v] = self.update_message_c_to_v(c, v, h, s_c, mu_v_to_c)\n",
    "            \n",
    "            mu_v_to_c = mu_v_to_c_new\n",
    "            mu_c_to_v = mu_c_to_v_new\n",
    "        \n",
    "        # 最終的なビリーフ計算\n",
    "        # print(l_v)\n",
    "        # print(self.b_v)\n",
    "        mu_v = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "\n",
    "        for v in range(num_nodes):\n",
    "            mu_v[v] = self.merginalization(v, l_v, h, mu_c_to_v, self.w, self.b)\n",
    "        \n",
    "        sigma_mu_v = self.hf_sigmoid(mu_v)\n",
    "        \n",
    "        return sigma_mu_v\n",
    "    \n",
    "    def update_message_v_to_c(self, v, c, l_v, h, mu_c_to_v, w, b):\n",
    "        num_edges = h.size(0)\n",
    "\n",
    "        message = l_v[v] * b[v]\n",
    "        h_row = h[:, v]\n",
    "\n",
    "        for c_prime in range(num_edges):\n",
    "            if h_row[c_prime] == 1 and c_prime != c:\n",
    "                # print(c)\n",
    "                # print('c_prime')\n",
    "                # print(c_prime)\n",
    "                # print('v')\n",
    "                # print(v)\n",
    "                message += mu_c_to_v[c_prime, v] * w[c_prime, v]\n",
    "\n",
    "        return message\n",
    "\n",
    "    def update_message_c_to_v(self, c, v, h, s_c, mu_v_to_c):\n",
    "        num_nodes = h.size(1)\n",
    "\n",
    "        message = 1\n",
    "        h_line = h[c, :]\n",
    "\n",
    "        # print(h[c, :])\n",
    "        for v_prime in range(num_nodes):\n",
    "            if h_line[v_prime] == 1 and v_prime != v:\n",
    "                message *= torch.tanh(mu_v_to_c[v_prime, c] / 2)\n",
    "        \n",
    "        message = (-1) ** s_c[c] * 2 * torch.atanh(message)\n",
    "\n",
    "        return message\n",
    "    \n",
    "    def merginalization(self, v, l_v, h, mu_c_to_v, w, b):\n",
    "        num_edges = h.size(0)\n",
    "\n",
    "        message = l_v[v] * b[v]\n",
    "        h_row = h[:, v]\n",
    "        # print('h_row')\n",
    "        # print(h_row)\n",
    "\n",
    "        for c in range(num_edges):\n",
    "            if h_row[c] == 1:\n",
    "                message += mu_c_to_v[c, v] * w[c, v]\n",
    "\n",
    "        return message\n",
    "    \n",
    "    def hf_sigmoid(self, x):\n",
    "        return 1 / (torch.exp(x) + 1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#continue with the NBP_oc class, some tool functions\n",
    "#NBP_ocクラスを継続し、いくつかのツール機能を追加する。\n",
    "def load_matrices(codeType, n, k, m_oc, m1, device):\n",
    "    \"\"\"reads in the check matrix for decoding as well as the dual matrix for checking decoding success\"\"\"\n",
    "    \"\"\"デコードのためのチェックマトリックスと、デコードの成功をチェックするためのデュアルマトリックスを読み込む\"\"\"\n",
    "    file_nameGx = \"./PCMs/\" + codeType + \"_\" + str(n) + \"_\" + str(\n",
    "        k) + \"/\" + codeType + \"_\" + str(n) + \"_\" + str(k) + \"_Gx.alist\"\n",
    "    file_nameGz = \"./PCMs/\" + codeType + \"_\" + str(n) + \"_\" + str(\n",
    "        k) + \"/\" + codeType + \"_\" + str(n) + \"_\" + str(k) + \"_Gz.alist\"\n",
    "    Gx = readAlist(file_nameGx)\n",
    "    Gz = readAlist(file_nameGz)\n",
    "\n",
    "    file_nameH = \"./PCMs/\" + codeType + \"_\" + str(n) + \"_\" + str(\n",
    "        k) + \"/\" + codeType + \"_\" + str(n) + \"_\" + str(k) + \"_H_\" + str(m_oc) + \".alist\"\n",
    "\n",
    "    H = readAlist(file_nameH)\n",
    "    H = torch.from_numpy(H).float().to(device)\n",
    "    # self.H = H\n",
    "    Hx = H[0:m1, :]\n",
    "    Hz = H[m1:m_oc, :]\n",
    "    # Gx = torch.from_numpy(Gx).float()\n",
    "    # Gz = torch.from_numpy(Gz).float()\n",
    "    # Hx = torch.from_numpy(Hx).float()\n",
    "    # Hz = torch.from_numpy(Hz).float()\n",
    "\n",
    "\n",
    "    # first dim for batches.\n",
    "    # self.Hx = self.unsqueeze_batches(Hx).float().to(self.device)\n",
    "    # self.Hz = self.unsqueeze_batches(Hz).float().to(self.device)\n",
    "    # self.Gx = self.unsqueeze_batches(Gx).float().to(self.device)\n",
    "    # self.Gz = self.unsqueeze_batches(Gz).float().to(self.device)\n",
    "\n",
    "    # H = torch.cat((Hx, Hz), dim=1).float().to(device)\n",
    "    # self.H_reverse = 1 - self.H\n",
    "\n",
    "    return H, Hx, Hz\n",
    "\n",
    "\n",
    "def readAlist(directory):\n",
    "    '''\n",
    "    Reads in a parity check matrix (pcm) in A-list format from text file. returns the pcm in form of a numpy array with 0/1 bits as float64.\n",
    "    テキストファイルからAリスト形式のパリティチェック行列(pcm)を読み込み、float64として0/1ビットのnumpy配列形式でpcmを返す\n",
    "    '''\n",
    "\n",
    "    alist_raw = []\n",
    "    with open(directory, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            # remove trailing newline \\n and split at spaces:\n",
    "            line = line.rstrip().split(\" \")\n",
    "            # map string to int:\n",
    "            line = list(map(int, line))\n",
    "            alist_raw.append(line)\n",
    "    alist_numpy = alistToNumpy(alist_raw)\n",
    "    alist_numpy = alist_numpy.astype(float)\n",
    "    return alist_numpy\n",
    "\n",
    "\n",
    "def alistToNumpy(lines):\n",
    "    '''Converts a parity-check matrix in AList format to a 0/1 numpy array'''\n",
    "    nCols, nRows = lines[0]\n",
    "    if len(lines[2]) == nCols and len(lines[3]) == nRows:\n",
    "        startIndex = 4\n",
    "    else:\n",
    "        startIndex = 2\n",
    "    matrix = np.zeros((nRows, nCols), dtype=float)\n",
    "    for col, nonzeros in enumerate(lines[startIndex:startIndex + nCols]):\n",
    "        for rowIndex in nonzeros:\n",
    "            if rowIndex != 0:\n",
    "                matrix[rowIndex - 1, col] = 1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give parameters for the code and decoder\n",
    "n = 46\n",
    "k = 2\n",
    "m = 800 #number of checks, can also use 46 or 44\n",
    "m1 = m // 2\n",
    "m2 = m // 2\n",
    "n_iterations = 6\n",
    "codeType = 'GB'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "H, Hx, Hz = load_matrices(codeType, n, k, m, m1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([800, 46])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 46])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hx_reverse = 1 - Hx\n",
    "Hz_reverse = 1 - Hz\n",
    "H_v = torch.cat([Hz_reverse, Hx_reverse], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([800, 46])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_v.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        ...,\n",
       "        [1., 1., 0.,  ..., 0., 1., 0.],\n",
       "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 0., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 0.],\n",
       "        [1., 1., 1.,  ..., 1., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 1.,  ..., 1., 0., 1.],\n",
       "        [0., 0., 1.,  ..., 1., 1., 1.],\n",
       "        [0., 0., 1.,  ..., 1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_v = torch.randint(2, (n,)).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndrome = torch.matmul(H, e_v)\n",
    "syndrome = torch.remainder(syndrome, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([800])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syndrome.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of coded bits: 46\n",
      "M:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.float32\n",
      "H_tensor\n",
      "tensor([[0., 0., 0.,  ..., 0., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "H_v_tensor\n",
      "tensor([[1., 1., 1.,  ..., 0., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 1., 0., 1.],\n",
      "        [0., 0., 1.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 1.,  ..., 1., 1., 1.]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/101 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/101 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ogawa/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_9366/798975249.py\", line 46, in <module>\n",
      "    sigma_mu_v = model(l_v=l_v, h=H, s_c=syndrome, iterations=iterations)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ogawa/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_9366/3055839713.py\", line 38, in forward\n",
      "    mu_v_to_c_new[v, c] = self.update_message_v_to_c(v, c, l_v, h, mu_c_to_v, self.w, self.b)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_9366/3055839713.py\", line -1, in update_message_v_to_c\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ogawa/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ogawa/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ogawa/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ogawa/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ogawa/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ogawa/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ogawa/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/ogawa/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/ogawa/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ogawa/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/ogawa/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ogawa/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/ogawa/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/home/ogawa/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# 使用例\n",
    "seed = np.random.RandomState(0)\n",
    "\n",
    "k, n = H.shape\n",
    "print(\"Number of coded bits:\", n)\n",
    "\n",
    "iterations = 1\n",
    "l_v = torch.tensor([3.74899243611] * n)\n",
    "\n",
    "model = BeliefPropagation(num_nodes=n, num_edges=k)\n",
    "\n",
    "# sigma_mu_v = model(l_v=l_v, h=H_tensor, s_c=syndrome_tensor, iterations=iterations)\n",
    "# print(sigma_mu_v)\n",
    "# exit()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)  # 最適化手法\n",
    "\n",
    "O = torch.zeros((n // 2, n // 2))\n",
    "I = torch.eye(n // 2)\n",
    "\n",
    "OI = torch.cat((O, I), 1)\n",
    "IO = torch.cat((I, O), 1)\n",
    "\n",
    "M = torch.cat((OI, IO), 0)\n",
    "\n",
    "print('M:')\n",
    "print(M)\n",
    "print(M.dtype)\n",
    "\n",
    "# print('Error pattern:', e_v_tensor.to(torch.int32).numpy())\n",
    "# sigma_mu_v = model(l_v=l_v, h=H_tensor, s_c=s_c_tensor, iterations=iterations)\n",
    "# print('sigma_mu_v:')\n",
    "# print(sigma_mu_v.numpy())\n",
    "# exit()\n",
    "\n",
    "print('H_tensor')\n",
    "print(H)\n",
    "\n",
    "print('H_v_tensor')\n",
    "print(H_v)\n",
    "\n",
    "history = {'epoch': [], 'loss': []}\n",
    "for epoch in tqdm(range(101)):\n",
    "    optimizer.zero_grad()\n",
    "    # print(l_v[2])\n",
    "    sigma_mu_v = model(l_v=l_v, h=H, s_c=syndrome, iterations=iterations)\n",
    "\n",
    "    # print('H_v * M')\n",
    "    # print(torch.matmul(H_v_tensor, M).shape)\n",
    "\n",
    "    # print('x')\n",
    "    # print(torch.matmul(torch.matmul(H_v_tensor, M), e_v + sigma_mu_v).shape)\n",
    "\n",
    "    # print(e_v)\n",
    "    # print(sigma_mu_v)\n",
    "\n",
    "    loss = torch.sum(torch.abs(torch.sin((torch.pi / 2) * (torch.matmul(torch.matmul(H_v, M), e_v + sigma_mu_v)))))\n",
    "    # tqdm.write('loss: {loss}')\n",
    "\n",
    "    # criterion = nn.BCEWithLogitsLoss()  # 二値クロスエントロピー損失関数\n",
    "    # loss = criterion(sigma_mu_v, e_v)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "        history['epoch'].append(epoch)\n",
    "        history['loss'].append(loss.item())\n",
    "        print(sigma_mu_v)\n",
    "\n",
    "# 学習後のパラメータの値\n",
    "# print(\"Learned parameters:\")\n",
    "# print(\"b_v:\", model.b.data)\n",
    "# print(\"w:\", model.w.data)\n",
    "\n",
    "print('Final loss:', loss.item())\n",
    "print('Error pattern:', e_v.tolist())\n",
    "\n",
    "decoded_message = np.where(sigma_mu_v < 0.5, 0, 1)\n",
    "print(\"Decoded message:\", decoded_message)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Learning Curve')\n",
    "ax = fig.add_subplot(111, xlabel='epoch', ylabel='loss')\n",
    "\n",
    "ax.plot(history['epoch'], history['loss'], label = 'NBP')\n",
    "ax.plot(history['epoch'], [history['loss'][0]] * 11, label = 'BP')\n",
    "\n",
    "ax.legend()\n",
    "fig.savefig('qldpc_nbp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 3., 3., 3., 4., 4., 5., 6., 4., 3., 3., 3., 4., 3., 6., 5., 3., 3.,\n",
       "        4., 4., 3., 4., 4., 7., 2., 5., 2., 4., 4., 1., 3., 5., 5., 4., 4., 6.,\n",
       "        6., 4., 4., 6., 6., 7., 3., 3., 5., 4., 4., 5., 4., 7., 6., 6., 6., 8.,\n",
       "        5., 3., 4., 5., 3., 3., 5., 5., 4., 5., 5., 6., 5., 3., 5., 8., 4., 5.,\n",
       "        5., 3., 4., 5., 5., 7., 7., 6., 3., 6., 5., 3., 5., 2., 5., 4., 5., 3.,\n",
       "        5., 5., 5., 4., 3., 3., 4., 4., 5., 5., 6., 2., 4., 6., 4., 3., 7., 1.,\n",
       "        6., 6., 5., 4., 5., 4., 6., 4., 3., 4., 4., 3., 5., 3., 4., 5., 6., 5.,\n",
       "        6., 7., 5., 5., 4., 5., 3., 7., 2., 5., 3., 6., 5., 6., 4., 4., 6., 4.,\n",
       "        6., 5., 4., 6., 6., 6., 8., 4., 7., 4., 6., 6., 7., 4., 4., 6., 7., 7.,\n",
       "        5., 4., 3., 5., 5., 7., 5., 7., 4., 5., 5., 7., 7., 6., 6., 6., 4., 8.,\n",
       "        5., 3., 4., 2., 4., 2., 2., 4., 5., 3., 6., 5., 4., 6., 5., 5., 5., 4.,\n",
       "        6., 6., 7., 5., 5., 6., 6., 4., 8., 4., 4., 6., 6., 3., 3., 3., 6., 2.,\n",
       "        4., 3., 4., 4., 5., 5., 5., 3., 6., 7., 5., 4., 5., 6., 4., 6., 4., 5.,\n",
       "        4., 7., 3., 6., 6., 3., 5., 4., 8., 5., 4., 5., 6., 7., 3., 5., 4., 6.,\n",
       "        3., 4., 3., 4., 5., 3., 4., 4., 7., 5., 7., 7., 5., 6., 5., 5., 3., 6.,\n",
       "        5., 5., 6., 4., 7., 6., 6., 5., 5., 5., 4., 6., 5., 2., 3., 5., 4., 4.,\n",
       "        3., 3., 7., 4., 6., 5., 5., 5., 5., 5., 6., 7., 5., 8., 3., 7., 5., 3.,\n",
       "        5., 5., 5., 5., 5., 3., 4., 6., 5., 4., 7., 6., 3., 7., 7., 6., 7., 5.,\n",
       "        8., 6., 6., 4., 5., 5., 5., 4., 4., 5., 4., 3., 4., 4., 7., 5., 5., 1.,\n",
       "        4., 4., 7., 4., 6., 4., 4., 4., 2., 3., 4., 4., 5., 3., 5., 4., 4., 3.,\n",
       "        5., 4., 3., 6., 6., 5., 3., 2., 4., 0., 4., 4., 5., 4., 3., 6., 6., 3.,\n",
       "        4., 7., 4., 6., 4., 5., 5., 4., 6., 3., 6., 4., 2., 6., 3., 5., 5., 6.,\n",
       "        6., 7., 4., 5., 2., 4., 3., 4., 5., 3., 5., 3., 2., 3., 5., 5., 4., 5.,\n",
       "        5., 3., 5., 3., 5., 4., 3., 4., 3., 8., 4., 6., 4., 6., 5., 3., 5., 2.,\n",
       "        4., 2., 3., 3., 7., 7., 4., 6., 5., 8., 3., 4., 5., 4., 5., 5., 4., 3.,\n",
       "        3., 2., 5., 3., 4., 5., 6., 3., 7., 6., 6., 4., 4., 7., 4., 3., 4., 4.,\n",
       "        5., 5., 4., 3., 4., 4., 4., 2., 3., 3., 7., 4., 4., 3., 6., 6., 2., 6.,\n",
       "        2., 7., 6., 8., 3., 8., 6., 5., 3., 3., 5., 5., 7., 4., 7., 3., 3., 5.,\n",
       "        6., 5., 6., 5., 5., 5., 6., 5., 7., 5., 8., 5., 6., 4., 3., 6., 7., 3.,\n",
       "        5., 6., 7., 7., 6., 3., 4., 4., 5., 7., 4., 6., 5., 5., 6., 6., 4., 7.,\n",
       "        6., 5., 5., 6., 4., 4., 3., 5., 8., 4., 6., 5., 5., 5., 6., 4., 6., 5.,\n",
       "        7., 3., 4., 5., 4., 4., 3., 4., 2., 4., 6., 5., 5., 3., 4., 4., 4., 4.,\n",
       "        2., 5., 5., 5., 4., 6., 3., 2., 2., 5., 5., 5., 3., 5., 5., 5., 5., 3.,\n",
       "        3., 6., 6., 6., 6., 3., 5., 4., 5., 7., 5., 4., 2., 5., 4., 5., 4., 6.,\n",
       "        5., 3., 4., 6., 5., 7., 6., 3., 4., 5., 6., 5., 7., 8., 6., 5., 5., 3.,\n",
       "        6., 7., 6., 7., 5., 4., 4., 5., 5., 5., 7., 5., 6., 4., 4., 8., 5., 6.,\n",
       "        3., 4., 7., 7., 6., 6., 5., 8., 6., 3., 4., 5., 6., 5., 4., 6., 4., 5.,\n",
       "        2., 5., 7., 4., 6., 4., 4., 7., 6., 3., 6., 8., 5., 7., 5., 6., 5., 5.,\n",
       "        7., 5., 4., 7., 4., 8., 6., 5., 4., 4., 7., 7., 2., 4., 4., 4., 5., 4.,\n",
       "        6., 7., 7., 5., 3., 4., 7., 6., 7., 7., 5., 5., 5., 5., 5., 4., 4., 3.,\n",
       "        4., 6., 4., 5., 6., 3., 5., 7., 4., 3., 5., 5., 5., 5., 5., 3., 4., 4.,\n",
       "        2., 7., 5., 5., 3., 4., 5., 2., 5., 4., 5., 5., 6., 6., 3., 4., 5., 8.,\n",
       "        7., 4., 6., 2., 3., 5., 5., 5., 4., 3., 1., 3., 3., 4., 3., 3., 2., 5.,\n",
       "        4., 6., 6., 6., 5., 4., 4., 3., 6., 6., 4., 6., 3., 4., 3., 6., 4., 4.,\n",
       "        4., 6., 7., 3., 5., 5., 5., 4.], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synsyndrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BeliefPropagation' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ogawa/Quantum-Neural-BP4-demo/NBP_2.ipynb セル 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bnode190403/home/ogawa/Quantum-Neural-BP4-demo/NBP_2.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BeliefPropagation' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeliefPropagation()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BeliefPropagation' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ogawa/Quantum-Neural-BP4-demo/NBP_2.ipynb セル 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bnode190403/home/ogawa/Quantum-Neural-BP4-demo/NBP_2.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/anaconda3/envs/NBP_demo/lib/python3.11/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BeliefPropagation' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: b, Device: cuda:0\n",
      "Parameter: w, Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# モデルのパラメータのデバイスを確認\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter: {name}, Device: {param.device}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NBP_demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
